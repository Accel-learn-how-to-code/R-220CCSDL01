source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/VinhPham.R')
source('D:/Code/R/B42/VinhPham.R')
source('D:/Code/R/B42/VinhPham.R')
source('D:/Code/R/B42/VinhPham.R')
source('D:/Code/R/B42/VinhPham.R')
source('D:/Code/R/B42/VinhPham.R')
source('D:/Code/R/B42/sample.R')
source('D:/Code/R/B42/sample.R')
source('D:/Code/R/B42/sample.R')
source('D:/Code/R/B42/sample.R')
source('D:/Code/R/B42/sample.R', encoding = 'UTF-8')
source('D:/Code/R/B42/sample.R', encoding = 'UTF-8')
source('D:/Code/R/B42/sample.R', encoding = 'UTF-8')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R', encoding = 'UTF-8')
source('D:/Code/R/B42/SolarElectric.R', encoding = 'UTF-8')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/SolarElectric.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
install.packages("jsonlite")
install.packages("jsonlite")
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
install.packages("stringr")
install.packages("stringr")
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/Muc43.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
rating
source('D:/Code/R/B42/ScrapingWebExample.R')
View(movies)
source('D:/Code/R/B42/ScrapingWebExample.R')
View(movies)
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
View(name)
name
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
install.packages("readr")
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingWebExample.R')
synopsis
source('D:/Code/R/B42/ScrapingWebExample.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
notificationTitles
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
content
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
content
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
content
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
content
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
titles
description
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
description
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
description
install.packages("stringr")
install.packages("stringr")
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
description
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
description
typeof(description)
str_replace_all(description, "([\n])", "")
description
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
description
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
description
titles
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
book_links
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
description
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
author
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
book_links
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
x = "https://ln.hako.re/xuat-ban/474-soi-va-gia-vi-tap-16"
novelPage = read_html(x)
author = novelPage %>% html_nodes(".publisher-name a") %>% html_text()
author
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
bookLinks
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
publishers
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
authors
artists
publishers
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
source('D:/Code/R/B42/ScrapingDaotaoUTE.R')
for (pageResult in 1 : 49){
link = paste("https://ln.hako.re/xuat-ban?page=", pageResult)
}
source('D:/Code/R/B42/lnHako2.R')
for (pageResult in 1 : 49){
link = paste("https://ln.hako.re/xuat-ban?page=", pageResult)
print(link)
}
for (pageResult in 1 : 49){
link = paste("https://ln.hako.re/xuat-ban?page=", pageResult)
print(link)
}
for (pageResult in 1 : 49){
link = paste0("https://ln.hako.re/xuat-ban?page=", pageResult)
print(link)
}
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
install.packages("xlsx")
library(rvest)
library(dplyr)
library(readr)
library(xlsx)
getPublisher = function(x) {
novelPage = read_html(x)
publisher = novelPage %>% html_nodes(".publisher-name a") %>% html_text()
return(publisher)
}
lnHako = data.frame()
for (pageResult in 1 : 3){
print(paste("Scrapping Page:", pageResult))
link = paste0("https://ln.hako.re/xuat-ban?page=", pageResult)
page = read_html(link)
bookLinks = page %>% html_nodes(".series-name") %>% html_attr("href")
titles = page %>% html_nodes(".series-name") %>% html_text()
description = page %>% html_nodes(".series-summary") %>% html_text()
authors = page %>% html_nodes("#licensed-list .col-md-6:nth-child(1) a") %>% html_text()
artists = page %>% html_nodes("#licensed-list .col-md-6:nth-child(2) a") %>% html_text()
publishers = sapply(bookLinks, FUN = getPublisher)
lnHako = rbind(lnHako, data.frame(titles, description, publishers, authors, artists, stringsAsFactors = FALSE))
print(paste("Scrapped Page:", pageResult))
}
print("Done!")
write.xlsx(lnHako, "lnHako.xlsx", sheetName = "Testtt", col.names = TRUE, row.names = TRUE, append = FALSE)
library(xlsx)
install.packages("xlsx")
library(xlsx)
library(readr)
library(xlsx)
library("xlsx")
library("xlsx")
library("xlsx")
library("xlsx")
library(rvest)
library(dplyr)
library(xlsx)
library(xlsx)
library(xlsx)
library(rvest)
library(dplyr)
library(readr)
library(xlsx)
getPublisher = function(x) {
novelPage = read_html(x)
publisher = novelPage %>% html_nodes(".publisher-name a") %>% html_text()
return(publisher)
}
lnHako = data.frame()
for (pageResult in 1 : 3){
print(paste("Scrapping Page:", pageResult))
link = paste0("https://ln.hako.re/xuat-ban?page=", pageResult)
page = read_html(link)
bookLinks = page %>% html_nodes(".series-name") %>% html_attr("href")
titles = page %>% html_nodes(".series-name") %>% html_text()
description = page %>% html_nodes(".series-summary") %>% html_text()
authors = page %>% html_nodes("#licensed-list .col-md-6:nth-child(1) a") %>% html_text()
artists = page %>% html_nodes("#licensed-list .col-md-6:nth-child(2) a") %>% html_text()
publishers = sapply(bookLinks, FUN = getPublisher)
lnHako = rbind(lnHako, data.frame(titles, description, publishers, authors, artists, stringsAsFactors = FALSE))
print(paste("Scrapped Page:", pageResult))
}
print("Done!")
write.xlsx(lnHako, "lnHako.xlsx", sheetName = "Testtt", col.names = TRUE, row.names = TRUE, append = FALSE)
library(rvest)
library(dplyr)
library(readr)
library(xlsx)
getPublisher = function(x) {
novelPage = read_html(x)
publisher = novelPage %>% html_nodes(".publisher-name a") %>% html_text()
return(publisher)
}
lnHako = data.frame()
for (pageResult in 1 : 3){
print(paste("Scrapping Page:", pageResult))
link = paste0("https://ln.hako.re/xuat-ban?page=", pageResult)
page = read_html(link)
bookLinks = page %>% html_nodes(".series-name") %>% html_attr("href")
titles = page %>% html_nodes(".series-name") %>% html_text()
description = page %>% html_nodes(".series-summary") %>% html_text()
authors = page %>% html_nodes("#licensed-list .col-md-6:nth-child(1) a") %>% html_text()
artists = page %>% html_nodes("#licensed-list .col-md-6:nth-child(2) a") %>% html_text()
publishers = sapply(bookLinks, FUN = getPublisher)
lnHako = rbind(lnHako, data.frame(titles, description, publishers, authors, artists, stringsAsFactors = FALSE))
print(paste("Scrapped Page:", pageResult))
}
print("Done!")
write.xlsx(lnHako, "lnHako.xlsx", sheetName = "Testtt", col.names = TRUE, row.names = TRUE, append = FALSE)
write.xlsx(lnHako, "lnHako.xlsx", sheetName = "Testtt222", col.names = TRUE, row.names = TRUE, append = FALSE)
library(rvest)
library(dplyr)
library(readr)
library(xlsx)
getPublisher = function(x) {
novelPage = read_html(x)
publisher = novelPage %>% html_nodes(".publisher-name a") %>% html_text()
return(publisher)
}
lnHako = data.frame()
for (pageResult in 1 : 3){
print(paste("Scrapping Page:", pageResult))
link = paste0("https://ln.hako.re/xuat-ban?page=", pageResult)
page = read_html(link)
bookLinks = page %>% html_nodes(".series-name") %>% html_attr("href")
titles = page %>% html_nodes(".series-name") %>% html_text()
description = page %>% html_nodes(".series-summary") %>% html_text()
authors = page %>% html_nodes("#licensed-list .col-md-6:nth-child(1) a") %>% html_text()
artists = page %>% html_nodes("#licensed-list .col-md-6:nth-child(2) a") %>% html_text()
publishers = sapply(bookLinks, FUN = getPublisher)
lnHako = rbind(lnHako, data.frame(titles, description, publishers, authors, artists, stringsAsFactors = FALSE))
print(paste("Scrapped Page:", pageResult))
}
print("Done!")
write.xlsx(lnHako, "lnHako.xlsx", sheetName = "Testtt", col.names = TRUE, row.names = TRUE, append = FALSE)
write.xlsx(lnHako, "lnHako.xlsx", sheetName = "Testtt222", col.names = TRUE, row.names = TRUE, append = TRUE)
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
publishers
publishers = sapply(bookLinks, FUN = getPublisher)
library(rvest)
library(dplyr)
library(xlsx)
getPublisher = function(x) {
novelPage = read_html(x)
publisher = novelPage %>% html_nodes(".publisher-name a") %>% html_text()
print(publisher)
return(publisher)
}
lnHako = data.frame()
for (pageResult in 1 : 3){
print(paste("Scrapping Page:", pageResult))
link = paste0("https://ln.hako.re/xuat-ban?page=", pageResult)
page = read_html(link)
bookLinks = page %>% html_nodes(".series-name") %>% html_attr("href")
titles = page %>% html_nodes(".series-name") %>% html_text()
description = page %>% html_nodes(".series-summary") %>% html_text()
authors = page %>% html_nodes("#licensed-list .col-md-6:nth-child(1) a") %>% html_text()
artists = page %>% html_nodes("#licensed-list .col-md-6:nth-child(2) a") %>% html_text()
publishers = sapply(bookLinks, FUN = getPublisher)
lnHako = rbind(lnHako, data.frame(titles, description, publishers, authors, artists, stringsAsFactors = FALSE))
print(paste("Scrapped Page:", pageResult))
}
print("Done!")
publishers
source('D:/Code/R/B42/lnHako2.R')
publishers
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
typeof(publishers)
source('D:/Code/R/B42/lnHako2.R')
View(getPublisher)
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
install.packages("tidyverse")
library(tidyverse)
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
BookID
lnBook$BookID
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
BookID <- paste0("BOOK",seq.int(nrow(lnBook)))
View(lnBook)
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
publishers
lnPublishers
source('D:/Code/R/B42/lnHako2.R')
publishers[1]
publishers[1,1]
publishers[0]
publishers[2]
publisher
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
publishers
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
publisher
publisher %>% distinct(publishers, .keep_all = TRUE)
lnPublishers %>% distinct(publishers, .keep_all = TRUE)
lnArtist %>% distinct(artists, .keep_all = TRUE)
BookID <- paste0("BOOK",seq.int(nrow(lnBook)))
publisherID <- paste0("PUB",seq.int(nrow(lnPublishers)))
artistID <- paste0("ART",seq.int(nrow(lnArtist)))
book = data.frame(BookID, lnBook)
publisher = data.frame(publisherID, lnPublishers)
artist = data.frame(artistID, lnArtist)
write.xlsx(book, "lnHako.xlsx", sheetName = "book", col.names = TRUE, append = FALSE)
write.xlsx(publisher, "lnHako.xlsx", sheetName = "publishers", col.names = TRUE, append = TRUE)
write.xlsx(artist, "lnHako.xlsx", sheetName = "artists", col.names = TRUE, append = TRUE)
source('D:/Code/R/B42/lnHako2.R')
publisher
lnPublishers
lnPublishers %>% distinct(publishers, .keep_all = TRUE)
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
sapply(book$publishers, function(value) which(publisher$publishers == value))
apply(book$publishers, function(value) which(publisher$publishers == value))
lapply(book$publishers, function(value) which(publisher$publishers == value))
sapply(book$publishers, function(value) which(publisher$publishers == value))
book$publisherID <- publisher$publisherID[match(book$publishers,publisher$publishers)];
book
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
source('D:/Code/R/B42/lnHako2.R')
library(xlsx)
library(rvest)
library(stringr)
#library(writexl)
#url <- 'http://xuanvinh.vn/msi'
url <- 'http://xuanvinh.vn/DELL'
#Reading the HTML code from the website
webpage <- read_html(url)
#scrape title of the product>
title_html <- html_nodes(webpage, '.product-title')
TenSP <- html_text(title_html)
LinkHinhAnh <- html_nodes(webpage, xpath="//*[@class='product-item']/div/a/img")%>%html_attr("src")
imgSource <- read_html(url) %>% html_nodes(".product-item:nth-child(1) img") %>% html_attr('src')
#dowLoad the Url Img
for(num in 1:length(LinkHinhAnh[[1]])){
temp=LinkHinhAnh[[1]][num]
imgName=str_sub(temp,28)
cat("Dowloading image: ", imgName,"\n")
imgName=paste0("E:\\CDCSDL_CK\\img",imgName)
download.file(temp,destfile = imgName,mode = "wb")
}
price_html <- html_nodes(webpage, 'p.fleft.gia')
GiaTienKhuyenMai <- html_text(price_html)
price_html <- html_nodes(webpage, 'p.fright.gia_cu')
GiaTien <- html_text(price_html)
product_item_html <- html_nodes(webpage, '.product-list ')
product_item <- html_text(product_item_html)
str_replace_all(product_item, "[\r\n]" , "")
df <- data.frame(TenSP= str_replace_all(TenSP, "[\r\n]" , ""),
LinkHinhAnh= str_replace_all(LinkHinhAnh, "[\r\n]" , ""),
GiaTienKhuyenMai= str_replace_all(GiaTienKhuyenMai, "[\r\n]" , ""),
GiaTien= str_replace_all(GiaTien, "[\r\n]" , ""))
LinkHinhAnh
LinkHinhAnh[[1]]
#loading the package:
#library(xml2)
library(xlsx)
library(rvest)
library(stringr)
#library(writexl)
#url <- 'http://xuanvinh.vn/msi'
url <- 'http://xuanvinh.vn/DELL'
#Reading the HTML code from the website
webpage <- read_html(url)
#scrape title of the product>
title_html <- html_nodes(webpage, '.product-title')
TenSP <- html_text(title_html)
LinkHinhAnh <- html_nodes(webpage, xpath="//*[@class='product-item']/div/a/img")%>%html_attr("src")
imgSource <- read_html(url) %>% html_nodes(".product-item:nth-child(1) img") %>% html_attr('src')
#dowLoad the Url Img
for(num in 1:length(LinkHinhAnh)){
temp=LinkHinhAnh[[num]]
imgName=str_sub(temp,28)
cat("Dowloading image: ", imgName,"\n")
imgName=paste0("E:\\CDCSDL_CK\\img",imgName)
download.file(temp,destfile = imgName,mode = "wb")
}
